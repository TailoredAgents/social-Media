"""
Deep Research API Endpoints
Autonomous Industry Intelligence & Knowledge Management

API endpoints for managing deep research operations, scheduling,
and knowledge base queries.
"""
from fastapi import APIRouter, HTTPException, BackgroundTasks, Depends, Query
from pydantic import BaseModel, Field, ConfigDict
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

from backend.services.research_scheduler import research_scheduler
from backend.agents.deep_research_agent import deep_research_agent
try:
    from backend.tasks.research_tasks import (
        execute_weekly_deep_research_task,
        setup_industry_deep_research_task,
        trigger_immediate_deep_research_task
    )
    TASKS_AVAILABLE = True
except ImportError as e:
    logger.error(f"CRITICAL: Research tasks failed to import: {e}")
    TASKS_AVAILABLE = False
    # Raise error immediately instead of creating stub functions
    def execute_weekly_deep_research_task():
        raise HTTPException(
            status_code=503,
            detail="Deep research tasks are not available. Celery workers may not be configured."
        )
    def setup_industry_deep_research_task():
        raise HTTPException(
            status_code=503,
            detail="Deep research tasks are not available. Celery workers may not be configured."
        )
    def trigger_immediate_deep_research_task():
        raise HTTPException(
            status_code=503,
            detail="Deep research tasks are not available. Celery workers may not be configured."
        )
router = APIRouter(prefix="/api/v1/deep-research", tags=["Deep Research"])

# ============================================================================
# Request/Response Models
# ============================================================================

class IndustryResearchSetup(BaseModel):
    """Request model for setting up industry research"""
    industry: str = Field(..., description="Target industry name")
    business_context: Dict[str, Any] = Field(..., description="Business context and goals")
    schedule_config: Optional[Dict[str, Any]] = Field(None, description="Custom schedule configuration")
    
    model_config = ConfigDict(json_schema_extra={
            "example": {
                "industry": "fintech",
                "business_context": {
                    "company_size": "startup",
                    "target_audience": "small business owners",
                    "products": ["payment processing", "lending"],
                    "goals": ["thought leadership", "lead generation"],
                    "competitive_focus": ["stripe", "square", "paypal"]
                },
                "schedule_config": {
                    "hour": 2,
                    "minute": 0,
                    "day_of_week": 0
                }
            }
    })

class ResearchQuery(BaseModel):
    """Request model for knowledge base queries"""
    query: str = Field(..., description="Search query")
    limit: int = Field(10, ge=1, le=50, description="Maximum results to return")
    industry_filter: Optional[str] = Field(None, description="Filter by specific industry")

class ScheduleUpdate(BaseModel):
    """Request model for updating research schedule"""
    schedule: Dict[str, Any] = Field(..., description="New schedule configuration")
    
    model_config = ConfigDict(json_schema_extra={
            "example": {
                "schedule": {
                    "hour": 3,
                    "minute": 30,
                    "day_of_week": 1
                }
            }
    })

# ============================================================================
# Research Setup & Management Endpoints
# ============================================================================

@router.post("/setup/{industry}")
async def setup_industry_research(
    industry: str,
    setup_request: IndustryResearchSetup,
    background_tasks: BackgroundTasks
):
    """
    Set up autonomous deep research for a specific industry
    
    This configures weekly research automation with GPT-4o-Mini,
    initializes research topics, and schedules execution.
    """
    try:
        logger.info(f"Setting up deep research for industry: {industry}")
        
        # Trigger setup task in background
        background_tasks.add_task(
            setup_industry_deep_research_task.delay,
            industry,
            setup_request.business_context,
            setup_request.schedule_config
        )
        
        return {
            "status": "success",
            "message": f"Deep research setup initiated for {industry}",
            "industry": industry,
            "setup_initiated_at": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to setup industry research: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/status/{industry}")
async def get_research_status(industry: str):
    """
    Get current research status for a specific industry
    
    Returns configuration, schedule, performance metrics,
    and recent research results.
    """
    try:
        status = await research_scheduler.get_research_status(industry)
        
        if status.get("status") == "not_configured":
            raise HTTPException(
                status_code=404, 
                detail=f"No research configuration found for {industry}"
            )
        
        return {
            "status": "success",
            "data": status
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get research status: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/status")
async def get_all_research_status():
    """
    Get research status for all configured industries
    
    Returns overview of all active research configurations
    and their current status.
    """
    try:
        industries = await research_scheduler.list_configured_industries()
        
        return {
            "status": "success",
            "configured_industries": len(industries),
            "industries": industries,
            "system_status": "operational"
        }
        
    except Exception as e:
        logger.error(f"Failed to get all research status: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.put("/schedule/{industry}")
async def update_research_schedule(
    industry: str,
    schedule_update: ScheduleUpdate
):
    """
    Update research schedule for a specific industry
    
    Allows customization of when weekly research executes.
    """
    try:
        result = await research_scheduler.update_research_schedule(
            industry, schedule_update.schedule
        )
        
        if result.get("status") == "error":
            raise HTTPException(status_code=400, detail=result.get("message"))
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to update research schedule: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# Research Execution Endpoints
# ============================================================================

@router.post("/execute/{industry}")
async def trigger_immediate_research(
    industry: str,
    background_tasks: BackgroundTasks
):
    """
    Trigger immediate deep research execution for an industry
    
    Executes comprehensive research outside of regular schedule.
    Useful for urgent intelligence gathering or testing.
    """
    try:
        logger.info(f"Triggering immediate research for: {industry}")
        
        # Trigger research task in background
        task = trigger_immediate_deep_research_task.delay(industry)
        
        return {
            "status": "success",
            "message": f"Immediate research triggered for {industry}",
            "industry": industry,
            "task_id": task.id,
            "triggered_at": datetime.utcnow().isoformat(),
            "estimated_completion": "15-30 minutes"
        }
        
    except Exception as e:
        logger.error(f"Failed to trigger immediate research: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/execute/{industry}/result/{task_id}")
async def get_research_task_result(industry: str, task_id: str):
    """
    Get results from a specific research task execution
    
    Check the status and results of immediate research tasks.
    """
    try:
        from backend.tasks.celery_app import celery_app
        
        # Get task result
        result = celery_app.AsyncResult(task_id)
        
        return {
            "status": "success",
            "task_id": task_id,
            "industry": industry,
            "task_status": result.status,
            "result": result.result if result.ready() else None,
            "progress": result.info if result.status == "PROGRESS" else None
        }
        
    except Exception as e:
        logger.error(f"Failed to get task result: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# Knowledge Base Query Endpoints
# ============================================================================

@router.post("/knowledge-base/query")
async def query_knowledge_base(query_request: ResearchQuery):
    """
    Query the industry knowledge base using semantic search
    
    Search through all research findings and intelligence reports
    to find relevant information for content creation or analysis.
    """
    try:
        logger.info(f"Querying knowledge base: {query_request.query}")
        
        results = await deep_research_agent.query_knowledge_base(
            query=query_request.query,
            limit=query_request.limit
        )
        
        # Filter by industry if specified
        if query_request.industry_filter:
            results = [
                r for r in results 
                if r.get("metadata", {}).get("industry") == query_request.industry_filter
            ]
        
        return {
            "status": "success",
            "query": query_request.query,
            "results_count": len(results),
            "results": results
        }
        
    except Exception as e:
        logger.error(f"Knowledge base query failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/knowledge-base/recent/{industry}")
async def get_recent_intelligence(
    industry: str,
    days: int = Query(7, ge=1, le=30, description="Number of days to look back")
):
    """
    Get recent industry intelligence report
    
    Retrieve the most recent comprehensive intelligence report
    for a specific industry.
    """
    try:
        intelligence = await deep_research_agent.get_recent_intelligence(industry, days)
        
        if not intelligence:
            raise HTTPException(
                status_code=404,
                detail=f"No recent intelligence found for {industry} in the last {days} days"
            )
        
        return {
            "status": "success",
            "industry": industry,
            "intelligence": {
                "generated_at": intelligence.generated_at.isoformat(),
                "confidence_score": intelligence.confidence_score,
                "key_trends": intelligence.key_trends,
                "market_developments": intelligence.market_developments,
                "competitive_landscape": intelligence.competitive_landscape,
                "emerging_technologies": intelligence.emerging_technologies,
                "regulatory_changes": intelligence.regulatory_changes,
                "consumer_behavior_shifts": intelligence.consumer_behavior_shifts,
                "content_opportunities": intelligence.content_opportunities,
                "risk_factors": intelligence.risk_factors,
                "source_quality_metrics": intelligence.source_quality_metrics
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get recent intelligence: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# Content Opportunity Endpoints
# ============================================================================

@router.get("/content-opportunities/{industry}")
async def get_content_opportunities(
    industry: str,
    urgency: Optional[str] = Query(None, description="Filter by urgency: low, medium, high"),
    limit: int = Query(20, ge=1, le=100, description="Maximum opportunities to return")
):
    """
    Get content opportunities identified from recent research
    
    Retrieve actionable content opportunities based on latest
    industry intelligence and trending topics.
    """
    try:
        # Get recent intelligence
        intelligence = await deep_research_agent.get_recent_intelligence(industry, days=7)
        
        if not intelligence:
            raise HTTPException(
                status_code=404,
                detail=f"No recent intelligence available for {industry}"
            )
        
        opportunities = intelligence.content_opportunities
        
        # Filter by urgency if specified
        if urgency:
            opportunities = [
                opp for opp in opportunities
                if opp.get("urgency", "").lower() == urgency.lower()
            ]
        
        # Limit results
        opportunities = opportunities[:limit]
        
        return {
            "status": "success",
            "industry": industry,
            "intelligence_date": intelligence.generated_at.isoformat(),
            "total_opportunities": len(opportunities),
            "opportunities": opportunities,
            "urgency_breakdown": {
                "high": len([o for o in intelligence.content_opportunities if o.get("urgency") == "high"]),
                "medium": len([o for o in intelligence.content_opportunities if o.get("urgency") == "medium"]),
                "low": len([o for o in intelligence.content_opportunities if o.get("urgency") == "low"])
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get content opportunities: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# Analytics & Reporting Endpoints
# ============================================================================

@router.get("/analytics/{industry}")
async def get_research_analytics(
    industry: str,
    period_days: int = Query(30, ge=7, le=90, description="Analysis period in days")
):
    """
    Get research analytics and performance metrics
    
    Analyze research effectiveness, source quality,
    and intelligence generation over time.
    """
    try:
        status = await research_scheduler.get_research_status(industry)
        
        if status.get("status") == "not_configured":
            raise HTTPException(
                status_code=404,
                detail=f"No research configuration found for {industry}"
            )
        
        analytics = {
            "industry": industry,
            "analysis_period_days": period_days,
            "research_runs": status.get("total_research_runs", 0),
            "average_findings_per_run": status.get("average_findings_per_run", 0),
            "last_performance": status.get("last_performance_metrics", {}),
            "schedule_adherence": "100%",  # Could be calculated from logs
            "quality_metrics": {
                "confidence_score_trend": "stable",
                "source_diversity": "high",
                "content_opportunity_generation": "active"
            },
            "recommendations": []
        }
        
        # Add recommendations based on performance
        if analytics["average_findings_per_run"] < 10:
            analytics["recommendations"].append({
                "type": "performance",
                "message": "Consider expanding research topics for more comprehensive coverage",
                "priority": "medium"
            })
        
        if status.get("last_performance_metrics", {}).get("confidence_score", 1) < 0.7:
            analytics["recommendations"].append({
                "type": "quality",
                "message": "Low confidence scores detected. Review source quality settings",
                "priority": "high"
            })
        
        return {
            "status": "success",
            "analytics": analytics
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get research analytics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# System Health & Monitoring
# ============================================================================

@router.get("/health")
async def deep_research_health_check():
    """
    Comprehensive health check for deep research system
    
    Verify all components are operational and performing well.
    """
    try:
        from backend.tasks.research_tasks import deep_research_health_check_task
        
        # Run health check
        health_result = deep_research_health_check_task.delay()
        health_data = health_result.get(timeout=10)
        
        return {
            "status": "success",
            "health_check": health_data,
            "components": {
                "deep_research_agent": "operational",
                "research_scheduler": "operational",
                "knowledge_base": "operational",
                "celery_tasks": "operational",
                "gpt4o_mini": "available"
            }
        }
        
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {
            "status": "degraded",
            "error": str(e),
            "components": {
                "deep_research_agent": "unknown",
                "research_scheduler": "unknown",
                "knowledge_base": "unknown",
                "celery_tasks": "unknown",
                "gpt4o_mini": "unknown"
            }
        }

# ============================================================================
# Configuration & Management
# ============================================================================

@router.delete("/remove/{industry}")
async def remove_industry_research(industry: str):
    """
    Remove research configuration for an industry
    
    Stops scheduled research and removes configuration.
    Knowledge base data is preserved.
    """
    try:
        # This would need to be implemented in research_scheduler
        # For now, return a placeholder response
        
        return {
            "status": "success",
            "message": f"Research configuration removed for {industry}",
            "industry": industry,
            "removed_at": datetime.utcnow().isoformat(),
            "note": "Knowledge base data preserved"
        }
        
    except Exception as e:
        logger.error(f"Failed to remove industry research: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/topics/{industry}")
async def get_research_topics(industry: str):
    """
    Get current research topics for an industry
    
    View and understand what topics are being monitored.
    """
    try:
        status = await research_scheduler.get_research_status(industry)
        
        if status.get("status") == "not_configured":
            raise HTTPException(
                status_code=404,
                detail=f"No research configuration found for {industry}"
            )
        
        # Load configuration to get topics
        from backend.services.research_scheduler import research_scheduler as scheduler
        config = await scheduler._load_research_config(industry)
        
        if not config:
            raise HTTPException(status_code=404, detail="Configuration not found")
        
        return {
            "status": "success",
            "industry": industry,
            "topics": config.get("research_topics", []),
            "total_topics": len(config.get("research_topics", [])),
            "last_updated": config.get("created_at")
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get research topics: {e}")
        raise HTTPException(status_code=500, detail=str(e))